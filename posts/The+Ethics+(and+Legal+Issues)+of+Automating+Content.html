<head><title>Ramblings</title><link href='http://fonts.googleapis.com/css?family=Allura' rel='stylesheet' type='text/css'><meta name="viewport" content="width=device-width; initial-scale=1.0; user-scalable=0;"><style>a{color:#000000;}</style></head><body><div style="width:100%; position:absolute; top:20; left:0;"><h1 align="center" style="font-family: 'Allura', cursive; font-size:60px;">Ramblings</h1><div style="position:absolute; top:120; left:15%; width:70%; font-size:18px; line-height:1.2;"><h2><p>The Ethics (and Legal Issues) of Automating Content</p>
</h2><p>At the bottom of the <a href="https://news.google.com">Google News</a> homepage is this rather interesting quote: &quot;The selection and placement of stories on this page were determined automatically by a computer program.&quot; I&#39;d never noticed it before; come to think of it, that&#39;s probably Google&#39;s intention in tucking that disclaimer at the bottom, where most people won&#39;t look (but the lawyers are just as happy).

</p>
<p>But, my criticisms of the need for such a disclaimer aside, it brings up an interesting point. If someone takes offense at a portrayal of themselves by, ultimately, an unthinking machine, what recourse are they left with? While it is absolutely wonderful that this problem exists at all, it will only become trickier to deal with as the state-of-the-art improves.

</p>
<p>Unfortunately, the courts, as far as I can tell, have not directly dealt with the issue of defamation by a computer. So, now, we get to the interesting part. While I am certainly not a lawyer, it would appear that, at least in the United States, a program cannot commit libel (assuming that it is only mentioning public figures). In the <a href="http://www.law.cornell.edu/supct/html/historics/USSC_CR_0376_0254_ZO.html">majority opinion</a> <a href="http://en.wikipedia.org/wiki/New_York_Times_Co._v._Sullivan">in New York Times v. Sullivan</a>, the bar is set at content created &quot;with knowledge that it was false or with reckless disregard of whether it was false or not.&quot; There are two ways I see an algorithmically-generated story being contested as libel: (1) there was a bug present which caused an error in content generation or structuring or (2) a human interfered in the normal operation of said program. In the first case, the argument that the program had &quot;knowledge&quot; that the information was false is poor, as it is (in theory) in any products best interests to be accurate. In the second, however, the test of &quot;actual malice&quot; is met, albeit not by the program, but by a human. I quite honestly have no idea who would then get slapped with the lawsuit, but it would seem to me that there is at least something of a case there.

</p>
<p>This brings us to ethics, and, by necessity, to my personal views on the subject. The manipulation of a supposedly-unbiased computer &quot;author&quot; to personal ends is a gross ethical wrongdoing. However, things get somewhat murkier from here. If at all possible, automated systems should be entirely separate from their human counterparts. That way, there can be no accusations of human misconduct. To that end, the following is my policy on touching content generated by my own project, <a href="https://nflscorebot.github.com/">NFLScoreBot</a> and <a href="https://twitter.com/#!/dpearson_/scorebots">friends</a>:

</p>
<ol>
<li><p>Content may be deleted or regenerated if a software bug prevented the generation of an accurate summary.</p>
</li>
<li><p>Content may be deleted or regenerated if a problem with a data source prevented the generation of an accurate summary.</p>
</li>
<li><p>Content should be generated as quickly as possible, regardless of the involved parties and my personal opinions thereof.</p>
</li>
<li><p>If content is deleted as outlined in (1) or (2), it should be regenerated as quickly as possible, regardless of the involved parties and my personal opinions thereof.</p>
</li>
<li><p>Generated content will never be manipulated by a human in any way.</p>
</li>
<li><p>The same algorithms will be used for all content generation.</p>
</li>
</ol>
<p>All of that said, open source software, for full transparency, is probable best for automatic content generation. Unfortunately, I&#39;m not currently able to release any of the ScoreBots yet.</p>
<br/><div style="padding:15px; background-color:#fffacd;">If you like this post, you might want to check out my current project, <a href="http://twitter.com/nflscorebot">NFLScoreBot</a>.</div><br/><br/><span> -- October 22, 2012</span><br/><br/></div></div><script type="text/javascript">var _gaq = _gaq || [];_gaq.push(['_setAccount', 'UA-29421539-1']);_gaq.push(['_trackPageview']);(function() {var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);})();</script></div></body>